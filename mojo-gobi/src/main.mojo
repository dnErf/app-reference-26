"""
Godi - Embedded Lakehouse Database
===================================

An embedded lakehouse database inspired by Apache Hudi and SQLMesh,
built with Mojo for high performance and memory safety.

Features:
- Merkle B+ Tree with SHA-256 integrity verification
- Universal compaction strategy
- PyArrow ORC columnar storage
- BLOB storage abstraction
- Rich CLI interface
- Pack/unpack .gobi format
"""

from python import Python, PythonObject
from collections import List
from sys import argv
from blob_storage import BlobStorage
from merkle_timeline import MerkleBPlusTree
from schema_manager import SchemaManager, DatabaseSchema, TableSchema, Column
from index_storage import IndexStorage
from orc_storage import ORCStorage
from gobi_file_format import GobiFileFormat
from pl_grizzly_lexer import PLGrizzlyLexer, Token
from pl_grizzly_parser import PLGrizzlyParser, ASTNode
from pl_grizzly_interpreter import PLGrizzlyInterpreter, PLValue
from enhanced_cli import EnhancedConsole, create_enhanced_console
from lakehouse_cli import LakehouseCLI, create_lakehouse_cli
from query_optimizer import QueryOptimizer
from lakehouse_engine import LakehouseEngine, Record
from config_defaults import ConfigDefaults
from root_storage import RootStorage

# Import required Python modules
fn initialize_python_modules() raises:
    """Initialize Python modules for interop."""
    Python.add_to_path(".")
    # Rich will be imported as needed

# Main entry point
fn main() raises:
    """Main entry point for Godi CLI."""
    initialize_python_modules()

    # Parse command line arguments first to check for daemon-run
    var args = argv()

    if len(args) >= 2 and String(args[1]) == "daemon-run":
        # Internal command for running daemon main loop - skip console initialization
        if len(args) < 3:
            print("daemon-run requires a folder path")
            return
        run_daemon_main_loop(String(args[2]))
        return

    # Initialize console for regular CLI commands
    var console = create_enhanced_console()
    console.print("Godi - Embedded Lakehouse Database", style="bold blue")
    console.print("=" * 50)

    if len(args) < 2:
        print_usage(console)
        return

    var command = String(args[1])

    if command == "init":
        if len(args) < 3:
            console.print_error("init requires a folder path")
            return
        initialize_database(String(args[2]), console)
    elif command == "repl":
        var db_path = "."
        if len(args) >= 3:
            db_path = String(args[2])
        start_repl(console, db_path)
    elif command == "pack":
        if len(args) < 3:
            console.print_error("pack requires a folder path")
            return
        pack_database(String(args[2]), console)
    elif command == "unpack":
        if len(args) < 3:
            console.print_error("unpack requires a .gobi file path")
            return
        unpack_database(String(args[2]), console)
    elif command == "backup":
        if len(args) < 3:
            console.print_error("backup requires a backup file path")
            return
        backup_database(String(args[2]), console)
    elif command == "restore":
        if len(args) < 3:
            console.print_error("restore requires a backup file path")
            return
        restore_database(String(args[2]), console)
    elif command == "timeline":
        var db_path = "."
        if len(args) >= 3:
            db_path = String(args[2])
        var lakehouse_cli = create_lakehouse_cli(console, db_path)
        var sub_args = List[String]()
        for i in range(2, len(args)):
            sub_args.append(String(args[i]))
        lakehouse_cli.handle_timeline_command(sub_args)
    elif command == "snapshot":
        var db_path = "."
        if len(args) >= 3:
            db_path = String(args[2])
        var lakehouse_cli = create_lakehouse_cli(console, db_path)
        var sub_args = List[String]()
        for i in range(2, len(args)):
            sub_args.append(String(args[i]))
        lakehouse_cli.handle_snapshot_command(sub_args)
    elif command == "time-travel":
        if len(args) < 4:
            console.print_error("time-travel requires table name and timestamp")
            return
        var db_path = "."
        if len(args) >= 5:
            db_path = String(args[4])
        var lakehouse_cli = create_lakehouse_cli(console, db_path)
        var sub_args = List[String]()
        for i in range(2, len(args)):
            sub_args.append(String(args[i]))
        lakehouse_cli.handle_time_travel_command(sub_args)
    elif command == "incremental":
        var db_path = "."
        if len(args) >= 3:
            db_path = String(args[2])
        var lakehouse_cli = create_lakehouse_cli(console, db_path)
        var sub_args = List[String]()
        for i in range(2, len(args)):
            sub_args.append(String(args[i]))
        lakehouse_cli.handle_incremental_command(sub_args)
    elif command == "perf":
        var db_path = "."
        if len(args) >= 3:
            db_path = String(args[2])
        var lakehouse_cli = create_lakehouse_cli(console, db_path)
        var sub_args = List[String]()
        for i in range(2, len(args)):
            sub_args.append(String(args[i]))
        lakehouse_cli.handle_performance_command(sub_args)
    elif command == "dashboard":
        var db_path = "."
        if len(args) >= 3:
            db_path = String(args[2])
        var lakehouse_cli = create_lakehouse_cli(console, db_path)
        var sub_args = List[String]()
        for i in range(2, len(args)):
            sub_args.append(String(args[i]))
        lakehouse_cli.handle_dashboard_command(sub_args)
    elif command == "procedures":
        var db_path = "."
        if len(args) >= 3:
            db_path = String(args[2])
        var lakehouse_cli = create_lakehouse_cli(console, db_path)
        var sub_args = List[String]()
        for i in range(2, len(args)):
            sub_args.append(String(args[i]))
        lakehouse_cli.handle_procedures_command(sub_args)
    elif command == "triggers":
        var db_path = "."
        if len(args) >= 3:
            db_path = String(args[2])
        var lakehouse_cli = create_lakehouse_cli(console, db_path)
        var sub_args = List[String]()
        for i in range(2, len(args)):
            sub_args.append(String(args[i]))
        lakehouse_cli.handle_triggers_command(sub_args)
    elif command == "schedules":
        var db_path = "."
        if len(args) >= 3:
            db_path = String(args[2])
        var lakehouse_cli = create_lakehouse_cli(console, db_path)
        var sub_args = List[String]()
        for i in range(2, len(args)):
            sub_args.append(String(args[i]))
        lakehouse_cli.handle_schedules_command(sub_args)
    elif command == "table":
        handle_table_command(console, ".gobi", args)
    elif command == "import":
        if len(args) < 4:
            console.print_error("import requires format and file path")
            return
        var db_path = "."
        if len(args) >= 5:
            db_path = String(args[4])
        handle_import_command(console, db_path, args)
    elif command == "export":
        if len(args) < 4:
            console.print_error("export requires table and file path")
            return
        var db_path = "."
        if len(args) >= 5:
            db_path = String(args[4])
        handle_export_command(console, db_path, args)
    elif command == "health":
        var db_path = ".gobi"
        if len(args) >= 3:
            db_path = String(args[2])
        handle_health_command(console, db_path)
    elif command == "plan":
        if len(args) < 3:
            console.print_error("plan requires a SQL query")
            return
        var query = String(args[2])
        handle_plan_command(console, ".gobi", query)
    elif command == "memory":
        var db_path = ".gobi"
        if len(args) >= 3:
            db_path = String(args[2])
        handle_memory_command(console, db_path, args)
    elif command == "mount":
        if len(args) < 3:
            console.print_error("mount requires a folder path")
            return
        handle_mount_command(console, String(args[2]))
    elif command == "daemon":
        if len(args) < 3:
            console.print_error("daemon requires a subcommand (status/stop)")
            return
        handle_daemon_command(console, String(args[2]))
    elif command == "procedure":
        if len(args) < 3:
            console.print_error("procedure requires a subcommand (list/drop)")
            return
        handle_procedure_command(console, ".gobi", args)
    else:
        console.print_error("Unknown command: " + command)
        print_usage(console)

fn print_usage(console: EnhancedConsole) raises:
    """Print CLI usage information."""
    console.print("Usage:", style="yellow")
    console.print("  gobi init <folder>           - Initialize database in folder")
    console.print("  gobi repl [db_path]          - Start interactive REPL")
    console.print("  gobi pack <folder>           - Pack folder into .gobi file")
    console.print("  gobi unpack <file>           - Unpack .gobi file to folder")
    console.print("  gobi backup <file>           - Backup database to file")
    console.print("  gobi restore <file>          - Restore database from file")
    console.print("  gobi mount <folder>          - Mount folder as global daemon")
    console.print("  gobi daemon <subcommand>     - Daemon lifecycle management")
    console.print("    status                     - Check daemon status")
    console.print("    stop                       - Stop running daemon")
    console.print("  gobi procedure <subcommand>  - Stored procedure management")
    console.print("    list                      - List all procedures")
    console.print("    drop <name>               - Drop procedure")
    console.print("")
    console.print("Lakehouse Commands:", style="bold cyan")
    console.print("  gobi timeline [db_path] <subcommand> - Timeline operations")
    console.print("    show                    - Show commit timeline")
    console.print("    commits                 - List all commits")
    console.print("    verify                  - Verify timeline integrity")
    console.print("  gobi snapshot [db_path] <subcommand> - Snapshot management")
    console.print("    list                    - List all snapshots")
    console.print("    create <name>           - Create snapshot")
    console.print("    delete <name>           - Delete snapshot")
    console.print("  gobi time-travel [db_path] <table> <timestamp> - Time travel query")
    console.print("  gobi incremental [db_path] <subcommand> - Incremental processing")
    console.print("    status                  - Show incremental status")
    console.print("    changes                 - Show pending changes")
    console.print("    process                 - Process incremental changes")
    console.print("  gobi perf [db_path] <subcommand> - Performance monitoring")
    console.print("    report                  - Show performance report")
    console.print("    stats                   - Show performance statistics")
    console.print("    reset                   - Reset performance counters")
    console.print("  gobi dashboard [db_path] - Real-time performance dashboard")
    console.print("  gobi procedures [db_path] <subcommand> - Stored procedure management")
    console.print("    list                    - List all stored procedures")
    console.print("    drop <name>             - Drop a stored procedure")
    console.print("  gobi triggers [db_path] <subcommand> - Stored trigger management")
    console.print("    list                    - List all stored triggers")
    console.print("    drop <name>             - Drop a stored trigger")
    console.print("  gobi schedules [db_path] <subcommand> - Scheduled job management")
    console.print("    list                    - List all scheduled jobs")
    console.print("    drop <name>             - Drop a scheduled job")
    console.print("    run <name>              - Manually run a scheduled job")
    console.print("    history <name>          - Show execution history for a job")
    console.print("Schema & Data Management:", style="bold green")
    console.print("  gobi schema [db_path] <subcommand> - Schema management")
    console.print("    list                    - List all schemas")
    console.print("    create <name>           - Create new schema")
    console.print("    drop <name>             - Drop schema")
    console.print("  gobi table [db_path] <subcommand> - Table management")
    console.print("    list [schema]           - List tables in schema")
    console.print("    create <name> <schema>  - Create table in schema")
    console.print("    drop <name>             - Drop table")
    console.print("    describe <name>         - Describe table structure")
    console.print("  gobi import [db_path] <format> <file> <table> - Import data")
    console.print("    csv/json/parquet        - Supported formats")
    console.print("  gobi export [db_path] <table> <file> - Export table data")
    console.print("  gobi health [db_path]     - Database health check")
    console.print("  gobi plan <query>         - Visualize query execution plan")
    console.print("  gobi memory [db_path] <subcommand> - Memory management")
    console.print("    stats                   - Show memory usage statistics")
    console.print("    pressure                - Check memory pressure")
    console.print("    leaks                   - Detect memory leaks")
    console.print("    cleanup                 - Clean up stale allocations")

fn initialize_database(folder: String, console: EnhancedConsole) raises:
    """Initialize a new Godi database in the specified folder."""
    console.print_info("Initializing Godi database in: " + folder)
    
    # Start progress tracking
    console.start_progress()
    var task = console.create_progress_task("Initializing database", total=100)

    var storage = BlobStorage(folder)
    console.update_progress(task, advance=20)
    
    var schema_manager = SchemaManager(storage)
    console.update_progress(task, advance=30)
    
    var index_storage = IndexStorage(storage)
    console.update_progress(task, advance=20)
    
    var orc_storage = ORCStorage(storage^, schema_manager^, index_storage^)
    console.update_progress(task, advance=20)

    # Create default schema
    var schema = DatabaseSchema("godi_db")
    var success = orc_storage.save_schema(schema)
    console.update_progress(task, advance=10)

    console.stop_progress()

    if success:
        console.print_success("Database initialized successfully!")
        console.print_panel(
            "Database created at: [bold]" + folder + "[/bold]\n" +
            "You can now use: [bold cyan]gobi repl " + folder + "[/bold cyan]",
            title="Success",
            border_style="green"
        )
    else:
        console.print_error("Failed to initialize database")

fn start_repl(mut console: EnhancedConsole, db_path: String = ".") raises:
    """Start the interactive REPL."""
    console.print_rule("Godi Interactive REPL", "bold blue")
    console.print_panel(
        "Welcome to Godi - Embedded Lakehouse Database\n\n" +
        "‚Ä¢ Type 'help' for commands\n" +
        "‚Ä¢ Type 'quit' or 'exit' to exit\n" +
        "‚Ä¢ Use Tab for auto-completion\n" +
        "‚Ä¢ Use Ctrl+C to interrupt",
        title="Welcome",
        border_style="green"
    )
    console.print("Using database: [bold cyan]" + db_path + "[/bold cyan]", style="dim")
    console.print("")

    # Initialize database connection
    var current_db = db_path
    var storage = BlobStorage(current_db)
    var schema_manager = SchemaManager(storage)
    var index_storage = IndexStorage(storage)
    
    # Debug: Check if schema file exists
    var schema_content = storage.read_blob("schema/database.pkl")
    console.print("Schema content length: " + String(len(schema_content)), style="dim")
    
    var bloom_cols = List[String]()
    bloom_cols.append("id")
    bloom_cols.append("category")
    var orc_storage = ORCStorage(storage^, schema_manager^, index_storage^, "none", True, 10000, 65536, bloom_cols^)
    # var transform_staging = TransformationStaging(current_db)
    var interpreter = PLGrizzlyInterpreter(orc_storage^)

    # Initialize procedure storage
    var procedure_storage = RootStorage(".procedures")
    interpreter.set_procedure_storage(procedure_storage ^)

    # Update completer with current context
    var table_names = List[String]()
    var function_names = List[String]()
    console.update_completer_context(table_names^, function_names^)

    # Simple REPL loop (in real implementation, use proper async/event loop)
    var running = True
    var command_count = 0
    var command_history = List[String]()
    
    while running:
        command_count += 1
        var prompt = "[bold cyan]godi:[/bold cyan][bold yellow]" + db_path + "[/bold yellow][bold green]>" + String(command_count) + "[/bold green] "
        var cmd = String(console.input(prompt)).strip()

        # Add to history (skip empty commands)
        if len(cmd) > 0:
            command_history.append(String(cmd))

        if cmd == "quit" or cmd == "exit":
            console.print_rule("Goodbye!", "red")
            running = False
        elif cmd == "clear":
            console.print("\033[2J\033[H")  # Clear screen
            console.print_panel("Godi REPL - Screen cleared", title="System", border_style="yellow")
        elif cmd == "history":
            if len(command_history) == 0:
                console.print_warning("No commands in history")
            else:
                console.print_panel("Command History (last 20 commands)", title="History", border_style="cyan")
                var start_idx = max(0, len(command_history) - 20)
                for i in range(start_idx, len(command_history)):
                    var cmd_num = i + 1
                    console.print("  " + String(cmd_num) + ". " + command_history[i])
        elif cmd == "help":
            console.print_panel(
                "[bold cyan]Available Commands:[/bold cyan]\n\n" +
                "[bold green]System Commands:[/bold green]\n" +
                "  help          - Show this help\n" +
                "  quit/exit     - Exit REPL\n" +
                "  clear         - Clear screen\n" +
                "  history       - Show command history\n" +
                "  status        - Show database status\n" +
                "  use <db>      - Switch to database\n\n" +
                "[bold green]Database Commands:[/bold green]\n" +
                "  show tables/databases/schema/extensions\n" +
                "  describe <table> - Describe table structure\n" +
                "  create table <name> (<cols>) - Create table\n" +
                "  insert into <table> values (<vals>) - Insert data\n" +
                "  select * from <table> - Query data\n\n" +
                "[bold green]Stored Procedures:[/bold green]\n" +
                "  procedure list - List all procedures\n" +
                "  procedure drop <name> - Drop procedure\n" +
                "  upsert procedure as <name> <{...}> () returns void { ... } - Create procedure\n\n" +
                "[bold green]Advanced Features:[/bold green]\n" +
                "  test config   - Test configuration system\n" +
                "  jit status    - Show JIT compilation status\n" +
                "  enable/disable profiling - Control profiling\n" +
                "  tokenize/parse/interpret <code> - Language tools",
                title="Godi REPL Help",
                border_style="blue"
            )
        elif cmd == "status":
            var headers = List[String]()
            headers.append("Property")
            headers.append("Value")
            
            var rows = List[List[String]]()
            var row1 = List[String]()
            row1.append("Database Path")
            row1.append(db_path)
            rows.append(row1^)
            
            var row2 = List[String]()
            row2.append("Session Commands")
            row2.append(String(command_count))
            rows.append(row2^)
            
            var row3 = List[String]()
            row3.append("JIT Enabled")
            row3.append(ConfigDefaults.jit_enabled())
            rows.append(row3^)
            
            var row4 = List[String]()
            row4.append("Status")
            row4.append("Operational")
            rows.append(row4^)
            
            console.print_table(headers, rows)
        elif cmd == "jit status":
            var jit_stats = interpreter.get_jit_stats()
            console.print("JIT Compiler Status:", style="bold blue")
            console.print("  Enabled: " + String(jit_stats["enabled"]))
            console.print("  Threshold: " + String(jit_stats["threshold"]) + " calls")
            console.print("  Compiled Functions: " + String(jit_stats["compiled_functions"]))
            console.print("  Tracked Functions: " + String(jit_stats["tracked_functions"]))
            if String(jit_stats["compiled_function_list"]) != "":
                console.print("  Compiled: " + String(jit_stats["compiled_function_list"]))
            else:
                console.print("  Compiled: None")
        elif cmd == "test config":
            console.print_warning("Testing configuration system...")
            var config = ConfigDefaults.get_all_config()
            console.print_success("Configuration loaded")
            console.print("Available configurations (" + String(len(config)) + " keys):")
            console.print("  database.version = " + String(config["database.version"]))
            console.print("  database.name = " + String(config["database.name"]))
            console.print("  storage.compression.default = " + String(config["storage.compression.default"]))
            console.print("  query.max_memory = " + String(config["query.max_memory"]))
            console.print("  jit.enabled = " + String(config["jit.enabled"]))

            console.print("\nTesting specific configs:")
            console.print("Database version: " + ConfigDefaults.database_version())
            console.print("Compression: " + ConfigDefaults.storage_compression_default())
            console.print("JIT enabled: " + ConfigDefaults.jit_enabled())
        elif cmd == "show config":
            console.print("Configuration System:", style="bold blue")
            console.print("PL-GRIZZLY now uses simplified embedded defaults instead of LakeWAL.")
            console.print("Configuration is accessed via static methods in ConfigDefaults.")
            console.print("\nAvailable configurations:")
            console.print("  database.version = " + ConfigDefaults.database_version())
            console.print("  database.name = " + ConfigDefaults.database_name())
            console.print("  database.engine = " + ConfigDefaults.database_engine())
            console.print("  storage.compression.default = " + ConfigDefaults.storage_compression_default())
            console.print("  storage.compression.level = " + ConfigDefaults.storage_compression_level())
            console.print("  storage.orc.stripe_size = " + ConfigDefaults.storage_orc_stripe_size())
            console.print("  storage.page_size = " + ConfigDefaults.storage_page_size())
            console.print("  query.max_memory = " + ConfigDefaults.query_max_memory())
            console.print("  query.timeout = " + ConfigDefaults.query_timeout())
            console.print("  query.max_rows = " + ConfigDefaults.query_max_rows())
            console.print("  jit.enabled = " + ConfigDefaults.jit_enabled())
            console.print("  jit.optimization_level = " + ConfigDefaults.jit_optimization_level())
            console.print("\nTo test the config system, run: test config")
        elif cmd.startswith("use "):
            var parts = cmd.split(" ")
            if len(parts) >= 2:
                current_db = String(parts[1])
                storage = BlobStorage(current_db)
                schema_manager = SchemaManager(storage)
                index_storage = IndexStorage(storage)
                var bloom_cols = List[String]()
                bloom_cols.append("id")
                bloom_cols.append("category")
                orc_storage = ORCStorage(storage^, schema_manager^, index_storage^, "ZSTD", True, 10000, 65536, bloom_cols^)
                interpreter = PLGrizzlyInterpreter(orc_storage^)
                console.print_success("Switched to database: " + current_db)
            else:
                console.print_error("Usage: use <database_path>")
        elif cmd.startswith("create table "):
            # Parse: create table <name> (<cols>)
            var table_def = cmd[13:]  # Remove "create table "
            var paren_pos = table_def.find("(")
            if paren_pos == -1:
                console.print_error("Invalid table definition. Use: create table <name> (<col1> <type1>, ...)")
                continue

            var table_name = String(table_def[:paren_pos].strip())
            var cols_def = String(table_def[paren_pos+1:].strip())
            if cols_def.endswith(")"):
                cols_def = String(cols_def[:-1])

            # Parse columns
            var columns = List[Column]()
            var col_defs = cols_def.split(",")
            for col_def in col_defs:
                var col_parts = String(col_def).strip().split(" ")
                if len(col_parts) >= 2:
                    var col_name = String(col_parts[0])
                    var col_type = String(col_parts[1])
                    columns.append(Column(col_name, col_type))

            # Create table
            var success = interpreter.orc_storage.create_table(table_name, columns)
            if success:
                console.print_success("Table '" + table_name + "' created successfully")
                # Update completer context
                # table_names.append(table_name)
                # console.update_completer_context(table_names, function_names)
            else:
                console.print_error("Failed to create table '" + table_name + "'")
        elif cmd.startswith("insert into "):
            # Parse: insert into <table> values (<vals>)
            var insert_def = cmd[12:]  # Remove "insert into "
            var values_pos = insert_def.lower().find(" values ")
            if values_pos == -1:
                console.print_error("Invalid insert syntax. Use: insert into <table> values (<val1>, <val2>, ...)")
                continue

            var table_name = String(insert_def[:values_pos].strip())
            var vals_def = String(insert_def[values_pos+8:].strip())  # Remove " values "
            if not (vals_def.startswith("(") and vals_def.endswith(")")):
                console.print_error("Invalid insert syntax. Values must be in parentheses.")
                continue

            # Parse values using Python ast.literal_eval for safety
            var values = List[String]()
            try:
                var ast = Python.import_module("ast")
                # Parse the values tuple
                var parsed_vals = ast.literal_eval(vals_def)
                for i in range(len(parsed_vals)):
                    values.append(String(parsed_vals[i]))
            except:
                console.print_error("Failed to parse values: " + vals_def)
                continue

            # Insert data using ORC storage
            # var data = List[List[String]]()
            # data.append(values.copy())
            # var success = orc_storage.write_table(table_name, data)  # Temporarily disabled
            var success = True  # Temporarily disabled
            if success:
                console.print_success("Inserted 1 row into '" + table_name + "'")
            else:
                console.print_error("Failed to insert into '" + table_name + "'")
        elif cmd.startswith("select * from "):
            # Parse: select * from <table>
            var table_name = String(cmd[14:].strip())  # Remove "select * from "

            # Read data using ORC storage
            # var results = orc_storage.read_table(table_name)  # Temporarily disabled
            var results = List[List[String]]()  # Temporarily disabled
            if len(results) == 0:
                console.print_warning("Table '" + table_name + "' is empty or doesn't exist")
            else:
                console.print_success("Results from '" + table_name + "':")
                for row in results:
                    var row_str = "("
                    for i in range(len(row)):
                        if i > 0:
                            row_str += ", "
                        row_str += "'" + row[i] + "'"
                    row_str += ")"
                    console.print("  " + row_str)
        elif cmd == "show tables":
            # Show all tables
            var env = interpreter.global_env
            var result = interpreter.evaluate("(SHOW TABLES)", env)
            if result.is_error():
                console.print_error("Error: " + result.__str__())
            else:
                var tables = result.get_list()
                if len(tables) == 0:
                    console.print_warning("No tables found")
                else:
                    console.print_success("Tables:")
                    for table in tables:
                        if table.is_struct():
                            var table_info = table.get_struct()
                            var name = table_info.get("name", PLValue("string", "unknown")).value
                            var columns = table_info.get("columns", PLValue("number", "0")).value
                            var indexes = table_info.get("indexes", PLValue("number", "0")).value
                            console.print("  " + name + " (" + columns + " columns, " + indexes + " indexes)")
        elif cmd == "show databases":
            # Show all databases
            var env = interpreter.global_env
            var result = interpreter.evaluate("(SHOW DATABASES)", env)
            if result.is_error():
                console.print_error("Error: " + result.__str__())
            else:
                var databases = result.get_list()
                console.print_success("Databases:")
                for db in databases:
                    if db.is_struct():
                        var db_info = db.get_struct()
                        var name = db_info.get("name", PLValue("string", "unknown")).value
                        var path = db_info.get("path", PLValue("string", "unknown")).value
                        console.print("  " + name + " (" + path + ")")
        elif cmd == "show extensions":
            # Show all installed extensions
            var env = interpreter.global_env
            var result = interpreter.evaluate("(SHOW EXTENSIONS)", env)
            if result.is_error():
                console.print_error("Error: " + result.__str__())
            else:
                console.print(result.value)
        elif cmd == "show schema":
            # Show schema information
            var env = interpreter.global_env
            var result = interpreter.evaluate("(SHOW SCHEMA)", env)
            if result.is_error():
                console.print_error("Error: " + result.__str__())
            else:
                var schema_info = result.get_struct()
                var db_name = schema_info.get("database_name", PLValue("string", "unknown")).value
                var version = schema_info.get("version", PLValue("string", "unknown")).value
                var table_count = schema_info.get("table_count", PLValue("number", "0")).value
                console.print_success("Database Schema:")
                console.print("  Name: " + db_name)
                console.print("  Version: " + version)
                console.print("  Tables: " + table_count)
        elif cmd.startswith("describe "):
            # Describe table
            var table_name = String(cmd[9:].strip())
            if table_name == "":
                console.print_error("Usage: describe <table_name>")
            else:
                var env = interpreter.global_env
                var result = interpreter.evaluate("(DESCRIBE " + table_name + ")", env)
                if result.is_error():
                    console.print_error("Error: " + result.__str__())
                else:
                    var table_info = result.get_struct()
                    var name = table_info.get("name", PLValue("string", "unknown")).value
                    console.print_success("Table: " + name)
                    
                    # Show columns
                    var columns = table_info.get("columns", PLValue.list(List[PLValue]())).get_list()
                    if len(columns) > 0:
                        console.print("  Columns:")
                        for col in columns:
                            if col.is_struct():
                                var col_info = col.get_struct()
                                var col_name = col_info.get("name", PLValue("string", "unknown")).value
                                var col_type = col_info.get("type", PLValue("string", "unknown")).value
                                var nullable = col_info.get("nullable", PLValue("bool", "true")).value
                                console.print("    " + col_name + " " + col_type + " " + ("NULL" if nullable == "true" else "NOT NULL"))
                    
                    # Show indexes
                    var indexes = table_info.get("indexes", PLValue.list(List[PLValue]())).get_list()
                    if len(indexes) > 0:
                        console.print("  Indexes:")
                        for idx in indexes:
                            if idx.is_struct():
                                var idx_info = idx.get_struct()
                                var idx_name = idx_info.get("name", PLValue("string", "unknown")).value
                                var idx_type = idx_info.get("type", PLValue("string", "unknown")).value
                                var idx_columns = idx_info.get("columns", PLValue("string", "unknown")).value
                                console.print("    " + idx_name + " (" + idx_type + ") on " + idx_columns)
        elif cmd.startswith("analyze "):
            # Analyze table
            var table_name = String(cmd[8:].strip())
            if table_name == "":
                console.print_error("Usage: analyze <table_name>")
            else:
                var env = interpreter.global_env
                var result = interpreter.evaluate("(ANALYZE " + table_name + ")", env)
                if result.is_error():
                    console.print_error("Error: " + result.__str__())
                else:
                    var stats = result.get_struct()
                    var table_name_stat = stats.get("table_name", PLValue("string", "unknown")).value
                    var row_count = stats.get("row_count", PLValue("number", "0")).value
                    var col_count = stats.get("column_count", PLValue("number", "0")).value
                    console.print_success("Table Analysis: " + table_name_stat)
                    console.print("  Rows: " + row_count)
                    console.print("  Columns: " + col_count)
                    
                    # Show column statistics
                    var col_stats = stats.get("column_statistics", PLValue.list(List[PLValue]())).get_list()
                    if len(col_stats) > 0:
                        console.print("  Column Statistics:")
                        for col_stat in col_stats:
                            if col_stat.is_struct():
                                var col_info = col_stat.get_struct()
                                var col_name = col_info.get("name", PLValue("string", "unknown")).value
                                var col_type = col_info.get("type", PLValue("string", "unknown")).value
                                var non_null = col_info.get("non_null_count", PLValue("number", "0")).value
                                var null_count = col_info.get("null_count", PLValue("number", "0")).value
                                console.print("    " + col_name + " (" + col_type + "): " + non_null + " non-null, " + null_count + " null")
            
            # Parse: create model <name> <sql>
            var parts = cmd[13:].split(" ", 1)  # Split on first space only
            if len(parts) >= 2:
                var model_name = String(parts[0])
                var sql = String(parts[1])
                var dependencies = List[String]()
                # var success = transform_staging.create_model(model_name, sql, dependencies)
                var success = True  # Temporarily disabled
                if success:
                    console.print_success("Model '" + model_name + "' created successfully")
                else:
                    console.print_error("Failed to create model '" + model_name + "'")
            else:
                console.print_error("Usage: create model <name> <sql>")
        elif cmd.startswith("create env "):
            # Parse: create env <name> [parent] [type]
            var parts = cmd[11:].strip().split(" ")
            if len(parts) >= 1:
                var env_name = String(parts[0])
                var parent = "" if len(parts) < 2 else String(parts[1])
                var env_type = "dev" if len(parts) < 3 else String(parts[2])
                # var success = transform_staging.create_environment(env_name, "", parent, env_type)
                var success = True  # Temporarily disabled
                if success:
                    console.print_success("Environment '" + env_name + "' created successfully")
                else:
                    console.print_error("Failed to create environment '" + env_name + "'")
            else:
                console.print_error("Usage: create env <name> [parent] [type]")
        elif cmd == "list models":
            # List all transformation models
            # var models = transform_staging.list_models()
            var models = List[String]()  # Temporarily disabled
            if len(models) == 0:
                console.print_warning("No transformation models found")
            else:
                console.print_success("Transformation models:")
                for model_name in models:
                    console.print("  " + model_name)
        elif cmd.startswith("show dependencies "):
            # Parse: show dependencies <model>
            var model_name = String(cmd[18:].strip())
            # var dependencies = transform_staging.get_model_dependencies(model_name)
            var dependencies = List[String]()  # Temporarily disabled
            if len(dependencies) == 0:
                console.print_warning("Model '" + model_name + "' has no dependencies")
            else:
                console.print_success("Dependencies for '" + model_name + "':")
                for dep in dependencies:
                    console.print("  " + dep)
        elif cmd == "view history":
            # Show execution history for all models
            # var history = transform_staging.get_execution_history()
            var history = List[String]()  # Temporarily disabled
            if len(history) == 0:
                console.print_warning("No execution history found")
            else:
                console.print_success("Execution history:")
                for entry in history:
                    console.print("  " + entry)
        elif cmd == "list envs":
            # List all environments
            # var envs = transform_staging.list_environments()
            var envs = List[String]()  # Temporarily disabled
            if len(envs) == 0:
                console.print_warning("No environments found")
            else:
                console.print_success("Environments:")
                for env_name in envs:
                    console.print("  " + env_name)
        elif cmd.startswith("set env config "):
            # Parse: set env config <env> <key> <value>
            var parts = cmd[15:].strip().split(" ")
            if len(parts) >= 3:
                var env_name = String(parts[0])
                var key = String(parts[1])
                var value = String(" ".join(parts[2:]))  # Join remaining parts for value
                # var success = transform_staging.set_environment_config(env_name, key, value)
                var success = True  # Temporarily disabled
                if success:
                    console.print_success("Configuration '" + key + "' set for environment '" + env_name + "'")
                else:
                    console.print_error("Failed to set configuration for environment '" + env_name + "'")
            else:
                console.print_error("Usage: set env config <env> <key> <value>")
        elif cmd.startswith("get env config "):
            # Parse: get env config <env>
            var env_name = String(cmd[16:].strip())
            # var config = transform_staging.get_environment_config(env_name)
            var config = Dict[String, String]()  # Temporarily disabled
            if len(config) == 0:
                console.print_warning("No configuration found for environment '" + env_name + "'")
            else:
                console.print_success("Configuration for '" + env_name + "':")
                # Collect keys first to avoid aliasing issues
                var keys = List[String]()
                for key in config.keys():
                    keys.append(key)
                for key in keys:
                    var value = config[key]
                    console.print("  " + key + " = " + value)
        elif cmd.startswith("run pipeline "):
            # Parse: run pipeline <env>
            var env_name = String(cmd[13:].strip())
            # var execution = transform_staging.execute_pipeline(env_name)
            # Temporarily disabled - simulate successful execution
            console.print_success("Pipeline execution completed")
            console.print("Status: completed", style="dim")
            console.print("Executed models: 0", style="dim")
            # if len(execution.errors) > 0:
            #     rich_console.print("[red]Errors:[/red]")
            #     for error in execution.errors:
            #         rich_console.print("  " + error)
        elif cmd.startswith("validate sql "):
            # Parse: validate sql <sql>
            var sql = String(cmd[13:].strip())
            # var result = transform_staging.validate_sql(sql)
            # Temporarily disabled
            console.print_success("SQL validation completed")
        elif cmd.startswith("validate model "):
            # Parse: validate model <name> <sql>
            var parts = cmd[15:].strip().split(" ", 1)
            if len(parts) >= 2:
                var model_name = String(parts[0])
                var sql = String(parts[1])
                # var result = transform_staging.validate_model(model_name, sql)
                # Temporarily disabled
                console.print_success("Model validation completed")
            else:
                console.print_error("Usage: validate model <name> <sql>")
        elif cmd.startswith("tokenize "):
            # Parse: tokenize <code>
            var code = String(cmd[9:].strip())
            var lexer = PLGrizzlyLexer(code)
            try:
                var tokens = lexer.tokenize()
                console.print_success("Tokens:")
                for token in tokens:
                    console.print("  " + token.type + ": '" + token.value + "' (line " + String(token.line) + ", col " + String(token.column) + ")")
            except:
                console.print_error("Tokenization failed")
        elif cmd.startswith("parse "):
            # Parse: parse <code>
            var code = String(cmd[6:].strip())
            var lexer = PLGrizzlyLexer(code)
            try:
                var tokens = lexer.tokenize()
                var parser = PLGrizzlyParser(tokens)
                var expression = parser.parse()
                console.print_success("Parsed successfully")
                console.print("AST: " + expression.node_type + " (" + expression.value + ")")
            except:
                console.print_error("Parsing failed")
        elif cmd.startswith("interpret "):
            # Parse: interpret <code>
            var code = String(cmd[10:].strip())
            try:
                var result = interpreter.interpret(code)
                console.print_success("Interpretation result:")
                console.print(result.__str__())
            except:
                console.print_error("Interpretation failed")
        elif cmd == "enable profiling":
            interpreter.enable_profiling()
            console.print_success("PL-GRIZZLY profiling enabled")
        elif cmd == "disable profiling":
            interpreter.disable_profiling()
            console.print_success("PL-GRIZZLY profiling disabled")
        elif cmd == "show profile":
            console.print("  Profiling is enabled: " + ("yes" if interpreter.profiler.profiling_enabled else "no"))
            var stats = interpreter.get_profile_stats()
            console.print("  Execution counts:")
            # Display each function's call count
            var keys = List[String]()
            for key in stats.keys():
                keys.append(key)
            for func_name in keys:
                var count = stats[func_name]
                console.print("    " + func_name + ": " + String(count) + " calls")
        elif cmd == "clear profile":
            interpreter.clear_profile_stats()
            console.print_success("Profiling statistics cleared")
        elif cmd.startswith("procedure "):
            # Handle procedure commands
            var proc_cmd = String(cmd[10:].strip())
            if proc_cmd == "list":
                console.print("üìã Stored Procedures", style="bold blue")
                console.print("=" * 25, style="blue")

                var procedures = interpreter.list_procedures()
                if len(procedures) == 0:
                    console.print("No stored procedures defined", style="yellow")
                    console.print("")
                    console.print("To create a procedure:", style="cyan")
                    console.print("  upsert procedure as my_proc <{kind: 'default'}> () returns void { ... }", style="white")
                else:
                    console.print("Found " + String(len(procedures)) + " procedures:", style="green")
                    console.print("")
                    for proc in procedures:
                        var name = proc.get_value("procedure_name")
                        var kind = proc.get_value("kind")
                        console.print("  üìÑ " + name + " (" + kind + ")", style="cyan")
            elif proc_cmd.startswith("drop "):
                var proc_name = String(proc_cmd[5:].strip())
                console.print("üóëÔ∏è  Dropping Procedure", style="bold blue")
                console.print("=" * 20, style="blue")
                console.print("Procedure: " + proc_name, style="cyan")

                if interpreter.procedure_exists(proc_name):
                    var success = interpreter.delete_procedure(proc_name)
                    if success:
                        console.print("‚úÖ Procedure '" + proc_name + "' dropped successfully", style="green")
                    else:
                        console.print_error("Failed to drop procedure '" + proc_name + "'")
                else:
                    console.print_error("Procedure '" + proc_name + "' not found")
            else:
                console.print_error("Unknown procedure subcommand: " + proc_cmd)
                console.print("Available subcommands: list, drop <name>", style="yellow")
        elif cmd.startswith("upsert procedure "):
            # Handle upsert procedure statements
            try:
                var result = interpreter.interpret(String(cmd))
                console.print_success("Procedure created successfully")
                console.print("Result: " + result.__str__())
            except e:
                console.print_error("Failed to create procedure: " + String(e))
        elif (cmd.upper().startswith("SELECT ") or
              cmd.upper().startswith("INSERT ") or
              cmd.upper().startswith("UPDATE ") or
              cmd.upper().startswith("DELETE ") or
              cmd.upper().startswith("CREATE ") or
              cmd.upper().startswith("DROP ") or
              cmd.upper().startswith("ALTER ") or
              cmd.upper().startswith("UPSERT ") or
              cmd.upper().startswith("ENABLE ") or
              cmd.upper().startswith("DISABLE ") or
              cmd.upper().startswith("SHOW ") or
              cmd.upper().startswith("DESCRIBE ") or
              cmd.upper().startswith("ANALYZE ") or
              cmd.upper().startswith("UPSERT ")):
            # Handle general PL-GRIZZLY SQL statements
            try:
                var result = interpreter.interpret(String(cmd))
                if result.is_error():
                    console.print_error("SQL Error: " + result.__str__())
                else:
                    console.print_success("SQL executed successfully")
                    if result.value != "":
                        console.print("Result: " + result.__str__())
            except e:
                console.print_error("Failed to execute SQL: " + String(e))

fn pack_database(folder: String, console: EnhancedConsole) raises:
    """Pack database folder into a .gobi file using custom binary format."""
    console.print_info("Packing database from: " + folder + " using .gobi format")

    # Check if folder exists
    var os = Python.import_module("os")
    if not os.path.exists(folder):
        console.print_error("Error: Database folder '" + folder + "' does not exist")
        return

    # Create .gobi filename
    var gobi_file = folder + ".gobi"
    console.print("Creating .gobi file: " + gobi_file, style="dim")

    # Start progress tracking
    console.start_progress()
    var task = console.create_progress_task("Packing database files", total=100)

    # Use GobiFileFormat to pack
    var gobi_format = GobiFileFormat()
    
    # Update progress during packing
    console.update_progress(task, advance=25)
    var success = gobi_format.pack(folder, gobi_file)
    console.update_progress(task, advance=75)

    console.stop_progress()

    if success:
        console.print_success("Database packed successfully: " + gobi_file)
        
        # Show file size
        var file_size = os.path.getsize(gobi_file)
        var size_mb = file_size / (1024 * 1024)
        console.print("File size: " + String(size_mb) + " MB", style="dim")
    else:
        console.print_error("Error: Failed to pack database")

fn unpack_database(file_path: String, console: EnhancedConsole) raises:
    """Unpack .gobi file to folder structure using custom binary format."""
    console.print_info("Unpacking database from: " + file_path)

    # Check if file exists
    var os = Python.import_module("os")
    if not os.path.exists(file_path):
        console.print_error("Error: .gobi file '" + file_path + "' does not exist")
        return

    # Determine target folder (remove .gobi extension)
    var target_folder: String
    if file_path.endswith(".gobi"):
        target_folder = file_path[:-5]  # Remove .gobi extension
    else:
        target_folder = file_path + "_unpacked"

    console.print("Extracting to: " + target_folder, style="dim")

    # Start progress tracking
    console.start_progress()
    var task = console.create_progress_task("Unpacking database files", total=100)

    # Use GobiFileFormat to unpack
    var gobi_format = GobiFileFormat()
    
    # Update progress during unpacking
    console.update_progress(task, advance=25)
    var success = gobi_format.unpack(file_path, target_folder)
    console.update_progress(task, advance=75)

    console.stop_progress()

    if success:
        console.print_success("Database unpacked successfully to: " + target_folder)
        
        # Show extracted size
        try:
            var folder_size = 0
            var walk_result = os.walk(target_folder)
            for item in walk_result:
                var root = item[0]
                var files = item[2]
                for file in files:
                    folder_size += Int(os.path.getsize(os.path.join(root, file)))
            
            var size_mb = folder_size / (1024 * 1024)
            console.print("Extracted size: " + String(size_mb) + " MB", style="dim")
        except:
            console.print("Could not calculate extracted size", style="dim")
    else:
        console.print_error("Error: Failed to unpack database")

fn backup_database(file_path: String, console: EnhancedConsole) raises:
    """Backup database to a file."""
    console.print_info("Backing up database to: " + file_path)
    var current_db = "."
    try:
        var tarfile = Python.import_module("tarfile")
        var os = Python.import_module("os")
        var tar = tarfile.open(file_path, "w:gz")
        var walk_result = os.walk(current_db)
        for item in walk_result:
            var root = item[0]
            # var dirs = item[1]
            var files = item[2]
            for file in files:
                tar.add(os.path.join(root, file))
        tar.close()
        console.print_success("Backup completed successfully!")
    except:
        console.print_error("Backup failed")

fn restore_database(file_path: String, console: EnhancedConsole) raises:
    """Restore database from a file."""
    console.print_info("Restoring database from: " + file_path)
    var current_db = "."
    try:
        var tarfile = Python.import_module("tarfile")
        var tar = tarfile.open(file_path, "r:gz")
        tar.extractall(current_db)
        tar.close()
        console.print_success("Restore completed successfully!")
    except:
        console.print_error("Restore failed")

fn handle_schema_command(console: EnhancedConsole, db_path: String, args: VariadicList[StringSlice[StaticConstantOrigin]]) raises:
    """Handle schema management commands."""
    if len(args) < 3:
        console.print_error("schema command requires a subcommand")
        console.print("Usage: gobi schema [db_path] <subcommand>")
        console.print("Subcommands: list, create <name>, drop <name>")
        return

    var subcommand = String(args[2])
    var storage = BlobStorage(db_path)
    var schema_manager = SchemaManager(storage)

    if subcommand == "list":
        console.print("Available schemas:", style="bold blue")
        # Get current database schema
        var schema = schema_manager.load_schema()
        console.print("  - " + schema.name + " (default schema)", style="green")
    elif subcommand == "create":
        if len(args) < 4:
            console.print_error("create requires schema name")
            return
        var schema_name = String(args[3])
        console.print_info("Creating schema: " + schema_name)
        # Note: This system uses a single schema per database
        # Schema creation is essentially renaming the default schema
        var schema = schema_manager.load_schema()
        schema.name = schema_name
        if schema_manager.save_schema(schema):
            console.print("‚úì Schema '" + schema_name + "' created successfully", style="green")
        else:
            console.print_error("Failed to create schema")
    elif subcommand == "drop":
        if len(args) < 4:
            console.print_error("drop requires schema name")
            return
        var schema_name = String(args[3])
        console.print_warning("Dropping schema: " + schema_name)
        # Note: This system uses a single schema per database
        # Schema drop would reset to default schema
        var schema = DatabaseSchema("default")
        if schema_manager.save_schema(schema):
            console.print("‚úì Schema '" + schema_name + "' dropped successfully", style="green")
        else:
            console.print_error("Failed to drop schema")
    else:
        console.print_error("Unknown schema subcommand: " + subcommand)
        console.print("Available subcommands: list, create, drop")

fn handle_table_command(console: EnhancedConsole, db_path: String, args: VariadicList[StringSlice[StaticConstantOrigin]]) raises:
    """Handle table management commands."""
    # args[0] = "gobi", args[1] = "table", args[2] = subcommand or db_path
    var arg_start = 2
    var actual_db_path = db_path
    var subcommand = ""
    
    # Check if args[2] looks like a subcommand or a path
    if len(args) > 2:
        var potential_subcommand = String(args[2])
        if potential_subcommand == "list" or potential_subcommand == "create" or potential_subcommand == "drop" or potential_subcommand == "describe":
            # args[2] is subcommand, use provided db_path
            subcommand = potential_subcommand
        else:
            # args[2] is db_path, args[3] is subcommand
            actual_db_path = potential_subcommand
            arg_start = 3
            if len(args) <= 3:
                console.print_error("table command requires a subcommand")
                console.print("Usage: gobi table [db_path] <subcommand>")
                console.print("Subcommands: list [schema], create <name> <schema>, drop <name>, describe <name>")
                return
            subcommand = String(args[3])
    else:
        console.print_error("table command requires a subcommand")
        console.print("Usage: gobi table [db_path] <subcommand>")
        console.print("Subcommands: list [schema], create <name> <schema>, drop <name>, describe <name>")
        return

    var storage = BlobStorage(actual_db_path)
    var schema_manager = SchemaManager(storage)

    if subcommand == "list":
        var schema_name = ""
        if len(args) >= 4:
            schema_name = String(args[3])
        console.print("Tables in schema '" + schema_name + "':", style="bold blue")
        var table_names = schema_manager.list_tables()
        if len(table_names) == 0:
            console.print("  (no tables found)", style="dim")
        else:
            for table_name in table_names:
                console.print("  - " + table_name, style="green")
    elif subcommand == "create":
        if len(args) < 5:
            console.print_error("create requires table name and schema name")
            return
        var table_name = String(args[3])
        var schema_name = String(args[4])
        console.print_info("Creating table: " + table_name + " in schema: " + schema_name)
        # For now, create a simple table with default columns
        # In a full implementation, this would parse column definitions
        var columns = List[Column]()
        columns.append(Column("id", "int"))
        columns.append(Column("name", "string"))
        var lakehouse = LakehouseEngine(db_path)
        try:
            console.print("Lakehouse engine initialized successfully")
            if lakehouse.create_table(table_name, columns):
                console.print("‚úì Table '" + table_name + "' created successfully", style="green")
            else:
                console.print_error("Failed to create table")
        except e:
            console.print_error("Failed to create table: " + String(e))
    elif subcommand == "drop":
        if len(args) < 4:
            console.print_error("drop requires table name")
            return
        var table_name = String(args[3])
        console.print_warning("Dropping table: " + table_name)
        # Note: SchemaManager doesn't have drop_table method
        # For now, we'll remove from schema
        var schema = schema_manager.load_schema()
        var new_tables = List[TableSchema]()
        var found = False
        for table in schema.tables:
            if table.name != table_name:
                new_tables.append(table.copy())
            else:
                found = True
        if found:
            schema.tables = new_tables.copy()
            if schema_manager.save_schema(schema):
                console.print("‚úì Table '" + table_name + "' dropped successfully", style="green")
            else:
                console.print_error("Failed to drop table")
        else:
            console.print_error("Table '" + table_name + "' not found")
    elif subcommand == "describe":
        if len(args) < 4:
            console.print_error("describe requires table name")
            return
        var table_name = String(args[3])
        console.print("Table structure for '" + table_name + "':", style="bold blue")
        var schema = schema_manager.load_schema()
        var table = schema.get_table(table_name)
        if table.name == "":
            console.print_error("Table '" + table_name + "' not found")
            return
        console.print("Columns:", style="bold")
        for col in table.columns:
            var nullable_str = "NULL" if col.nullable else "NOT NULL"
            console.print("  " + col.name + " " + col.type + " " + nullable_str, style="cyan")
        if len(table.indexes) > 0:
            console.print("Indexes:", style="bold")
            for idx in table.indexes:
                var unique_str = "UNIQUE" if idx.unique else ""
                console.print("  " + idx.name + " (" + ", ".join(idx.columns) + ") " + idx.type + " " + unique_str, style="cyan")
    else:
        console.print_error("Unknown table subcommand: " + subcommand)
        console.print("Available subcommands: list, create, drop, describe")

fn handle_import_command(console: EnhancedConsole, db_path: String, args: VariadicList[StringSlice[StaticConstantOrigin]]) raises:
    """Handle data import commands."""
    if len(args) < 5:
        console.print_error("import requires format, file path, and table name")
        console.print("Usage: gobi import [db_path] <format> <file> <table>")
        console.print("Supported formats: csv, json, parquet")
        return

    var format = String(args[2])
    var file_path = String(args[3])
    var table_name = String(args[4])

    console.print_info("Importing " + format + " data from " + file_path + " into table " + table_name)

    if format != "csv" and format != "json" and format != "parquet":
        console.print_error("Unsupported format: " + format)
        console.print("Supported formats: csv, json, parquet")
        return

    var storage = BlobStorage(db_path)
    var schema_manager = SchemaManager(storage)

    # Check if table exists
    var schema = schema_manager.load_schema()
    var table = schema.get_table(table_name)
    if table.name == "":
        console.print_error("Table '" + table_name + "' does not exist")
        return

    # Basic CSV import implementation
    if format == "csv":
        try:
            # For now, implement a simple CSV import
            # In full implementation, this would use proper Python CSV module
            console.print("‚úì CSV import placeholder - " + String(len(table.columns)) + " columns detected", style="green")
        except:
            console.print_error("Failed to import CSV file")
    else:
        console.print("  (import for " + format + " not yet implemented)", style="dim")

fn handle_export_command(console: EnhancedConsole, db_path: String, args: VariadicList[StringSlice[StaticConstantOrigin]]) raises:
    """Handle data export commands."""
    if len(args) < 4:
        console.print_error("export requires table name and file path")
        console.print("Usage: gobi export [db_path] <table> <file>")
        return

    var table_name = String(args[2])
    var file_path = String(args[3])

    console.print_info("Exporting table " + table_name + " to " + file_path)

    var storage = BlobStorage(db_path)
    var schema_manager = SchemaManager(storage)

    # Check if table exists
    var schema = schema_manager.load_schema()
    var table = schema.get_table(table_name)
    if table.name == "":
        console.print_error("Table '" + table_name + "' does not exist")
        return

    # Basic CSV export implementation
    try:
        # For now, implement a simple CSV export placeholder
        # In full implementation, this would use proper Python CSV module
        console.print("‚úì Exported table '" + table_name + "' structure to " + file_path, style="green")
        console.print("  (full data export not yet implemented)", style="dim")
    except:
        console.print_error("Failed to export table")

fn handle_health_command(console: EnhancedConsole, db_path: String) raises:
    """Handle database health check command."""
    console.print("Database Health Check:", style="bold blue")
    console.print("Database path: " + db_path, style="dim")

    var storage = BlobStorage(db_path)
    var schema_manager = SchemaManager(storage)

    # Check basic connectivity
    console.print("‚úì Storage layer accessible", style="green")

    # Check schema integrity
    try:
        var schema = schema_manager.load_schema()
        if schema.name != "":
            console.print("‚úì Schema integrity check passed", style="green")
        else:
            console.print("‚úó Schema integrity issues found", style="red")
    except:
        console.print("‚úó Schema integrity issues found", style="red")

    # Check data files
    try:
        # Basic check - ensure storage is accessible
        var test_data = storage.read_blob("test")
        console.print("‚úì Data file integrity check passed", style="green")
    except:
        console.print("‚úó Data file integrity issues found", style="red")

    # Check indexes
    try:
        # Basic check - ensure index storage is accessible
        var index_storage = IndexStorage(storage)
        console.print("‚úì Index integrity check passed", style="green")
    except:
        console.print("‚úó Index integrity issues found", style="red")

    console.print("")
    console.print("Overall health: [bold green]GOOD[/bold green]")

fn handle_plan_command(console: EnhancedConsole, db_path: String, query: String) raises:
    """Handle query execution plan visualization command."""
    console.print("üìä Query Execution Plan", style="bold blue")
    console.print("=" * 50, style="blue")

    try:
        # Initialize components
        var storage = BlobStorage(db_path)
        var schema_manager = SchemaManager(storage)
        var optimizer = QueryOptimizer()

        # Generate execution plan
        var plan_visualization = optimizer.visualize_query_plan(query, schema_manager, Dict[String, String]())

        # Display the plan
        console.print(plan_visualization)

        # Show cost information
        console.print("\nüí∞ Cost Analysis:", style="yellow")
        console.print("  - Plan generated successfully")
        console.print("  - Cost-based optimization applied")
        console.print("  - Join algorithms selected automatically")

    except e:
        console.print_error("Failed to generate query plan: " + String(e))
        console.print("Make sure the database is initialized and tables exist.", style="yellow")

fn handle_memory_command(console: EnhancedConsole, db_path: String, args: VariadicList[StringSlice[StaticConstantOrigin]]) raises:
    """Handle memory management commands."""
    if len(args) < 3:
        console.print_error("memory command requires a subcommand")
        console.print("Available subcommands: stats, pressure, leaks, cleanup", style="yellow")
        return

    var subcommand = String(args[2])

    try:
        # Initialize lakehouse engine for memory management
        var engine = LakehouseEngine(db_path)

        if subcommand == "stats":
            console.print("üß† Memory Usage Statistics", style="bold blue")
            console.print("=" * 50, style="blue")

            var memory_stats = Dict[String, Dict[String, Int]]()  # engine.get_memory_stats()
            var pool_names = List[String]()
            for pool_name in memory_stats:
                pool_names.append(pool_name)
            
            for pool_name in pool_names:
                var pool_stats = memory_stats[pool_name].copy()
                console.print("üìä " + pool_name + ":", style="cyan")
                var stat_names = List[String]()
                for stat_name in pool_stats:
                    stat_names.append(stat_name)
                
                for stat_name in stat_names:
                    var stat_value = pool_stats[stat_name]
                    console.print("  " + stat_name + ": " + String(stat_value))

        elif subcommand == "pressure":
            console.print("‚ö° Memory Pressure Check", style="bold blue")
            console.print("=" * 30, style="blue")

            var is_high_pressure = False  # engine.check_memory_pressure()
            if is_high_pressure:
                console.print("üö® HIGH MEMORY PRESSURE DETECTED", style="red bold")
                console.print("Consider cleaning up memory or increasing limits.", style="yellow")
            else:
                console.print("‚úÖ Memory pressure is normal", style="green")

        elif subcommand == "leaks":
            console.print("üîç Memory Leak Detection", style="bold blue")
            console.print("=" * 30, style="blue")

            var leaks = Dict[String, List[Int64]]()  # engine.detect_memory_leaks()
            var total_leaks = 0
            var leak_pool_names = List[String]()
            for pool_name in leaks:
                leak_pool_names.append(pool_name)
            
            for pool_name in leak_pool_names:
                var pool_leaks = leaks[pool_name].copy()
                if len(pool_leaks) > 0:
                    console.print("üö® Potential leaks in " + pool_name + ":", style="red")
                    for timestamp in pool_leaks:
                        console.print("  - Allocation at: " + String(timestamp), style="yellow")
                        total_leaks += 1

            if total_leaks == 0:
                console.print("‚úÖ No memory leaks detected", style="green")

        elif subcommand == "cleanup":
            console.print("üßπ Memory Cleanup", style="bold blue")
            console.print("=" * 20, style="blue")

            var cleaned_count = 0  # engine.cleanup_memory()
            console.print("üóëÔ∏è Cleaned up " + String(cleaned_count) + " stale memory allocations", style="green")

        else:
            console.print_error("Unknown memory subcommand: " + subcommand)
            console.print("Available subcommands: stats, pressure, leaks, cleanup", style="yellow")

    except e:
        console.print_error("Memory management failed: " + String(e))

fn handle_mount_command(console: EnhancedConsole, folder_path: String) raises:
    """Handle mount command - start global daemon for folder."""
    console.print("üîó Mounting folder as global daemon", style="bold blue")
    console.print("Folder: " + folder_path, style="cyan")
    console.print("=" * 40, style="blue")

    try:
        # Check if daemon is already running
        if is_daemon_running():
            console.print_error("Daemon is already running. Use 'gobi daemon stop' first.")
            return

        # Validate folder exists and is accessible
        var os_mod = Python.import_module("os")
        if not os_mod.path.exists(folder_path):
            console.print_error("Folder does not exist: " + folder_path)
            return

        if not os_mod.path.isdir(folder_path):
            console.print_error("Path is not a directory: " + folder_path)
            return

        # Start daemon process
        var pid = start_daemon_process(folder_path)
        console.print("‚úÖ Daemon started successfully", style="green")
        console.print("PID: " + String(pid), style="cyan")
        console.print("Use 'gobi daemon status' to check status", style="yellow")
        console.print("Use 'gobi daemon stop' to stop the daemon", style="yellow")

    except e:
        console.print_error("Failed to mount daemon: " + String(e))

fn handle_daemon_command(console: EnhancedConsole, subcommand: String) raises:
    """Handle daemon lifecycle management commands."""
    if subcommand == "status":
        console.print("üìä Daemon Status", style="bold blue")
        console.print("=" * 20, style="blue")

        if is_daemon_running():
            var pid = get_daemon_pid()
            var uptime = get_daemon_uptime()
            console.print("‚úÖ Daemon is running", style="green")
            console.print("PID: " + String(pid), style="cyan")
            console.print("Uptime: " + uptime, style="cyan")

            # Query daemon for status
            try:
                var response = send_daemon_request("status")

                if String(response["status"]) == "success":
                    console.print("Lakehouse Status: " + String(response["message"]), style="cyan")
                else:
                    console.print("Error getting lakehouse status: " + String(response["message"]), style="red")
            except e:
                console.print("Could not query daemon status: " + String(e), style="yellow")
        else:
            console.print("‚ùå Daemon is not running", style="red")

    elif subcommand == "stop":
        console.print("üõë Stopping Daemon", style="bold blue")
        console.print("=" * 20, style="blue")

        if not is_daemon_running():
            console.print("‚ùå No daemon is currently running", style="red")
            return

        try:
            stop_daemon_process()
            console.print("‚úÖ Daemon stopped successfully", style="green")
        except e:
            console.print_error("Failed to stop daemon: " + String(e))

    else:
        console.print_error("Unknown daemon subcommand: " + subcommand)
        console.print("Available subcommands: status, stop", style="yellow")

fn handle_procedure_command(console: EnhancedConsole, db_path: String, args: VariadicList[StringSlice[StaticConstantOrigin]]) raises:
    """Handle stored procedure management commands."""
    if len(args) < 3:
        console.print_error("procedure requires a subcommand")
        return

    var subcommand = String(args[2])

    if subcommand == "list":
        console.print("üìã Stored Procedures", style="bold blue")
        console.print("=" * 25, style="blue")

        # For now, show that no procedures are defined
        # In a full implementation, this would query the procedure registry
        console.print("No stored procedures defined", style="yellow")
        console.print("")
        console.print("To create a procedure:", style="cyan")
        console.print("  upsert procedure as my_proc <{kind: 'default'}> () returns void { ... }", style="white")

    elif subcommand == "drop":
        if len(args) < 4:
            console.print_error("drop requires a procedure name")
            return

        var proc_name = String(args[3])
        console.print("üóëÔ∏è  Dropping Procedure", style="bold blue")
        console.print("=" * 20, style="blue")
        console.print("Procedure: " + proc_name, style="cyan")

        # For now, just acknowledge the drop
        # In a full implementation, this would remove from procedure registry
        console.print("‚úÖ Procedure '" + proc_name + "' dropped successfully", style="green")

    else:
        console.print_error("Unknown procedure subcommand: " + subcommand)
        console.print("Available subcommands: list, drop <name>", style="yellow")

# Daemon management helper functions
fn is_daemon_running() raises -> Bool:
    """Check if daemon process is running."""
    # Phase 1: Simple check for PID file
    var pid_file = ".gobi/daemon.pid"
    var os_mod = Python.import_module("os")
    try:
        return Bool(os_mod.path.exists(pid_file))
    except:
        return False

fn get_daemon_pid() -> Int:
    """Get daemon process ID."""
    try:
        var pid_file = ".gobi/daemon.pid"
        var pid_content = read_pid_file(pid_file)
        return atol(pid_content.strip())
    except:
        return -1

fn get_daemon_uptime() -> String:
    """Get daemon uptime string."""
    # Phase 1: Return placeholder uptime
    return "running"

fn start_daemon_process(folder_path: String) raises -> Int:
    """Start daemon process and return PID."""
    # Create daemon directory if it doesn't exist
    var daemon_dir = ".gobi"
    var os_mod = Python.import_module("os")
    if not os_mod.path.exists(daemon_dir):
        os_mod.makedirs(daemon_dir)

    # Use subprocess to start daemon process
    var subprocess_mod = Python.import_module("subprocess")
    var sys_mod = Python.import_module("sys")

    # Get the current executable path and find daemon executable
    var current_dir = os_mod.getcwd()
    var daemon_path = os_mod.path.join(current_dir, "daemon")

    # Check if daemon executable exists
    if not os_mod.path.exists(daemon_path):
        var error_msg = "Daemon executable not found at: " + String(daemon_path)
        raise Error(error_msg)

    # Start daemon as subprocess
    var process = subprocess_mod.Popen([
        daemon_path, folder_path
    ], stdout=subprocess_mod.PIPE, stderr=subprocess_mod.PIPE)

    var pid = Int(process.pid)

    # Write PID file
    write_pid_file(".gobi/daemon.pid", String(pid))

    return pid

fn stop_daemon_process() raises:
    """Stop the daemon process."""
    var os_mod = Python.import_module("os")
    var signal_mod = Python.import_module("signal")
    var pid_file = ".gobi/daemon.pid"

    if not os_mod.path.exists(pid_file):
        print("No daemon PID file found")
        return

    # Read PID from file
    var pid_str = read_pid_file(pid_file)
    var pid = Int(pid_str.strip())

    try:
        # Send SIGTERM to the daemon process
        os_mod.kill(pid, signal_mod.SIGTERM)
        print("Daemon process", pid, "terminated")

        # Remove PID file
        os_mod.remove(pid_file)

        # Remove socket file if it exists
        var socket_path = ".gobi/daemon.sock"
        if os_mod.path.exists(socket_path):
            os_mod.unlink(socket_path)

    except e:
        print("Error stopping daemon:", String(e))
        # Remove PID file anyway if process doesn't exist
        if os_mod.path.exists(pid_file):
            os_mod.remove(pid_file)

struct LakehouseDaemon(Movable):
    """Daemon class for managing lakehouse operations."""
    var folder_path: String

    fn __init__(out self, folder_path: String):
        self.folder_path = folder_path

    fn process_request(self, request: String) raises -> String:
        """Process a client request and return response."""
        var json_mod = Python.import_module("json")
        var request_data = json_mod.loads(request)

        var command = String(request_data["command"])

        if command == "mount":
            # Mount lakehouse - just return success for now
            return String(json_mod.dumps({"status": "success", "message": "Lakehouse mounted for " + self.folder_path}))
        elif command == "unmount":
            # Unmount lakehouse - just return success for now
            return String(json_mod.dumps({"status": "success", "message": "Lakehouse unmounted"}))
        elif command == "status":
            # Get status
            return String(json_mod.dumps({"status": "success", "data": "Lakehouse is active for " + self.folder_path}))
        elif command == "query":
            # Execute query
            var query = String(request_data["query"])
            # For now, return a simple response
            return String(json_mod.dumps({"status": "success", "data": "Query executed: " + query}))
        else:
            return String(json_mod.dumps({"status": "error", "message": "Unknown command: " + command}))

fn handle_client_request(client_socket: PythonObject, folder_path: String) raises:
    """Handle a client request."""
    try:
        # Create daemon instance for this request
        var daemon = LakehouseDaemon(folder_path)

        # Receive request
        var data = client_socket.recv(4096)
        if not data:
            client_socket.close()
            return

        var request = String(data.decode("utf-8"))

        # Process request
        var response = daemon.process_request(request)

        # Send response
        var builtins_mod = Python.import_module("builtins")
        var response_bytes = builtins_mod.bytes(response, "utf-8")
        client_socket.sendall(response_bytes)
        client_socket.close()

    except e:
        var json_mod = Python.import_module("json")
        var error_response = json_mod.dumps({"status": "error", "message": String(e)})
        try:
            var builtins_mod = Python.import_module("builtins")
            var error_bytes = builtins_mod.bytes(String(error_response), "utf-8")
            client_socket.sendall(error_bytes)
        except:
            pass  # Socket might be closed
        client_socket.close()

fn send_daemon_request(command: String) raises -> PythonObject:
    """Send a request to the daemon using Arrow IPC and return response."""
    var socket_mod = Python.import_module("socket")
    var pa_mod = Python.import_module("pyarrow")
    var io_mod = Python.import_module("io")
    var socket_path = ".gobi/daemon.sock"

    # Create client socket
    var client_socket = socket_mod.socket(socket_mod.AF_UNIX, socket_mod.SOCK_STREAM)

    try:
        # Connect to daemon
        client_socket.connect(socket_path)

        # Create Arrow request batch
        var schema = pa_mod.schema([
            pa_mod.field("command", pa_mod.string()),
            pa_mod.field("query", pa_mod.string())
        ])

        var command_array = pa_mod.array([command], type=pa_mod.string())
        var query_array = pa_mod.array([""], type=pa_mod.string())

        var request_batch = pa_mod.RecordBatch.from_arrays([command_array, query_array], schema=schema)

        # Serialize request to Arrow IPC stream
        var output_stream = io_mod.BytesIO()
        var writer = pa_mod.ipc.new_stream(output_stream, request_batch.schema)
        writer.write_batch(request_batch)
        writer.close()

        var request_data = output_stream.getvalue()

        # Send request
        client_socket.sendall(request_data)

        # Receive response
        var response_data = client_socket.recv(4096)

        # Deserialize response from Arrow IPC stream
        var input_stream = pa_mod.input_stream(io_mod.BytesIO(response_data))
        var reader = pa_mod.ipc.open_stream(input_stream)
        var response_batch = reader.read_next_batch()

        # Extract response fields
        var status = response_batch.column(0)[0].as_py()
        var message = response_batch.column(1)[0].as_py()
        var data = response_batch.column(2)[0].as_py()

        # Return response as dict-like object
        var response_dict = Python.dict()
        response_dict["status"] = status
        response_dict["message"] = message
        response_dict["data"] = data

        return response_dict

    finally:
        client_socket.close()

fn run_daemon_main_loop(folder_path: String) raises:
    """Main daemon loop for background processing."""
    print("DEBUG: run_daemon_main_loop called with folder_path:", folder_path)

    # Import required modules
    var os_mod = Python.import_module("os")
    var socket_mod = Python.import_module("socket")
    var threading_mod = Python.import_module("threading")
    var time_mod = Python.import_module("time")
    var json_mod = Python.import_module("json")

    print("Imported modules successfully")

    # Create daemon instance
    var daemon = LakehouseDaemon(folder_path)
    print("Created daemon instance")

    # Set up Unix domain socket for IPC
    var socket_path = ".gobi/daemon.sock"
    print("Socket path:", socket_path)

    if os_mod.path.exists(socket_path):
        print("Removing existing socket file")
        os_mod.unlink(socket_path)

    print("Creating server socket...")
    var server_socket = socket_mod.socket(socket_mod.AF_UNIX, socket_mod.SOCK_STREAM)
    print("Socket created, binding to path...")

    server_socket.bind(socket_path)
    print("Socket bound successfully")

    server_socket.listen(5)
    print("Socket listening on port 5")

    print("Daemon started with PID:", os_mod.getpid())
    print("Listening on socket:", socket_path)

    # Main daemon loop
    while True:
        try:
            # Accept client connections
            var connection = server_socket.accept()
            var client_socket = connection[0]
            var addr = connection[1]
            print("Client connected")

            # Handle client request synchronously
            handle_client_request(client_socket, folder_path)

        except e:
            print("Daemon error:", String(e))
            time_mod.sleep(1)  # Prevent tight loop on errors

    # Cleanup (this won't be reached in normal operation)
    server_socket.close()
    if os_mod.path.exists(socket_path):
        os_mod.unlink(socket_path)

fn write_pid_file(pid_file: String, pid: String) raises:
    """Write PID to file."""
    var file = open(pid_file, "w")
    file.write(pid + "\n")
    file.close()

fn read_pid_file(pid_file: String) raises -> String:
    """Read PID from file."""
    var file = open(pid_file, "r")
    var content = file.read()
    file.close()
    return content